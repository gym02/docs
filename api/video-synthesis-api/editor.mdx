---
title: "API Reference"
description: "Complete reference for Video Synthesis API endpoints, parameters, and all 9 calling methods"
---

Video Synthesis API

NavTalk Video Synthesis API supports 9 different methods for generating digital human videos, categorized into three main types: **image-driven**, **video-driven**, and **built-in character-driven**.

# Endpoint

All requests are sent to the same endpoint:

```
POST https://app.navtalk.ai/generate
```

# API Call Overview

The following table provides a quick comparison of all 9 supported methods:

| Method | Visual Source | Audio Source | Use Case |
|--------|--------------|--------------|----------|
| ① Video + Audio URL | Video | Audio URL | Re-dub existing videos |
| ② Video + Audio Base64 | Video | Audio Base64 | Re-dub with local audio |
| ③ Video + Text (TTS) | Video | Text | Re-dub with TTS |
| ④ Image + Text (TTS) | Image | Text | Create talking head from photo |
| ⑤ Image + Audio URL | Image | Audio URL | Sync image with audio |
| ⑥ Image + Audio Base64 | Image | Audio Base64 | Sync image with local audio |
| ⑦ Built-in Character + Audio URL | Built-in | Audio URL | Use preset character with audio |
| ⑧ Built-in Character + Audio Base64 | Built-in | Audio Base64 | Use preset character with local audio |
| ⑨ Built-in Character + Text (TTS) | Built-in | Text | Use preset character with TTS |

## Detailed Examples

<AccordionGroup>
<Accordion title="① Video + Audio URL">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "video_url": "https://example.com/video.mp4",
    "audio_url": "https://example.com/audio.mp3"
  }'
```
</Accordion>

<Accordion title="② Video + Audio Base64">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "video_url": "https://example.com/video.mp4",
    "audio_base64": "base64-audio-data"
  }'
```
</Accordion>

<Accordion title="③ Video + Text (TTS)">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "video_url": "https://example.com/video.mp4",
    "content": "Welcome to NavTalk.",
    "voice": "nova"
  }'
```
</Accordion>

<Accordion title="④ Image + Text (TTS)">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "image_url": "https://example.com/photo.jpg",
    "content": "Welcome to NavTalk.",
    "voice": "echo"
  }'
```
</Accordion>

<Accordion title="⑤ Image + Audio URL">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "image_url": "https://example.com/photo.jpg",
    "audio_url": "https://example.com/audio.mp3"
  }'
```
</Accordion>

<Accordion title="⑥ Image + Audio Base64">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "image_url": "https://example.com/photo.jpg",
    "audio_base64": "base64-audio-data"
  }'
```
</Accordion>

<Accordion title="⑦ Built-in Character + Audio URL">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "character_name": "navtalk.Leo",
    "audio_url": "https://example.com/audio.mp3"
  }'
```
</Accordion>

<Accordion title="⑧ Built-in Character + Audio Base64">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "character_name": "navtalk.Leo",
    "audio_base64": "base64-audio-data"
  }'
```
</Accordion>

<Accordion title="⑨ Built-in Character + Text (TTS)">
```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "character_name": "navtalk.Leo",
    "content": "Welcome to NavTalk.",
    "voice": "fable"
  }'
```
</Accordion>
</AccordionGroup>

# Request Parameters

<ResponseField name="license" type="string" required>
API authorization key obtained from the [NavTalk dashboard](https://console.navtalk.ai/login#/dashboard).

**Example**: `"sk-xxx"`
</ResponseField>

<ResponseField name="video_url" type="string">
Public URL to a video file in MP4 or MOV format. Required for video-driven methods (methods ①, ②, ③).

The video must be publicly accessible via HTTP/HTTPS.

**Example**: `"https://example.com/video.mp4"`
</ResponseField>

<ResponseField name="image_url" type="string">
Public URL to an image file. Required for image-driven methods (methods ④, ⑤, ⑥).

The image must be publicly accessible via HTTP/HTTPS.

**Example**: `"https://example.com/photo.jpg"`
</ResponseField>

<ResponseField name="character_name" type="string">
Built-in character name. Required for built-in character methods (methods ⑦, ⑧, ⑨).

**Available characters**: `navtalk.Leo` and other built-in characters. See [Available Avatars](/api/resources/avatars) for the complete list.

**Example**: `"navtalk.Leo"`
</ResponseField>

<ResponseField name="audio_url" type="string">
Public URL to an audio file in MP3 or WAV format. Use this when you have a pre-recorded audio file.

The audio must be publicly accessible via HTTP/HTTPS.

**Example**: `"https://example.com/audio.mp3"`
</ResponseField>

<ResponseField name="audio_base64" type="string">
Base64-encoded audio data. Use this when you want to send audio data directly without hosting it online.

**Example**: `"base64-audio-data"`
</ResponseField>

<ResponseField name="content" type="string">
Text content for text-to-speech (TTS) synthesis. The API will convert this text to speech using the specified voice style.

**Example**: `"Welcome to NavTalk. This is my first digital human video!"`
</ResponseField>

<ResponseField name="voice" type="string">
Voice style for text-to-speech synthesis. Required when using the `content` parameter.

**Supported voices**: `alloy`, `ash`, `ballad`, `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, `verse`

See [Voice Styles](/api/video-synthesis-api/voice-styles) for complete descriptions and audio previews.

**Example**: `"echo"`
</ResponseField>

**Parameter Combinations:**

Choose one visual source and one audio source:

- **Video-driven**: `video_url` + (`audio_url` OR `audio_base64` OR `content`)
- **Image-driven**: `image_url` + (`audio_url` OR `audio_base64` OR `content`)
- **Built-in character**: `character_name` + (`audio_url` OR `audio_base64` OR `content`)

# Response Handling

All requests are processed asynchronously. The API returns a `task_id` that you use to query the status.

**Submit Request:**

```bash
curl -X POST "https://app.navtalk.ai/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "license": "sk-xxx",
    "character_name": "navtalk.Leo",
    "content": "Welcome to NavTalk.",
    "voice": "echo"
  }'
```

**Response:**

```json
{
  "status": "started",
  "task_id": "14cb760f-05ac-4fd3-a82c-e841f2f005d0"
}
```

<ResponseField name="status" type="string">
Initial status when the task is created. Always `"started"` in the initial response.
</ResponseField>

<ResponseField name="task_id" type="string">
Unique identifier for the generation task. Use this to query the task status.
</ResponseField>

**Query Status:**

Use the `task_id` to check processing status:

```bash
curl -X GET "https://api.navtalk.ai/query_status?license=YOUR_LICENSE&task_id=14cb760f-05ac-4fd3-a82c-e841f2f005d0"
```

**Response:**

```json
{
  "status": "done",
  "video_url": "https://easyaistorageaccount.blob.core.windows.net/easyai/uploadFiles/2025/05/09/xxx.mp4"
}
```

<ResponseField name="status" type="string">
Current status of the task. Possible values:
- `started`: Task created and processing
- `processing`: Video composition in progress
- `done`: Completed successfully, video URL available
- `failed`: Generation failed, check error message
</ResponseField>

<ResponseField name="video_url" type="string">
Public URL to the generated video file. Only present when `status` is `"done"`.

The video URL is publicly accessible and can be embedded directly in web pages, mobile apps, or downloaded for offline use.
</ResponseField>

<Tip>
Generation typically takes 10-30 seconds. Keep videos under 30 seconds for faster processing.
</Tip>

# Advanced Parameters

NavTalk supports optional advanced parameters for fine-tuning face cropping, mouth openness, and blending. These parameters are inherited from MuseTalk and should be used only when needed.

<ResponseField name="bbox_shift" type="number" default="0">
Vertical movement of the face crop box. Positive values shift the crop downward (making the mouth more open), while negative values shift upward (making the mouth less open).

**Range**: [-9, 9]

**Example**: `0`
</ResponseField>

<ResponseField name="extra_margin" type="number" default="10">
Pixels of extra margin added around the face crop. Increases buffer area to prevent clipping of chin, hair, or jaw.

**Range**: [0, 50]

**Example**: `10`
</ResponseField>

<ResponseField name="parsing_mode" type="string" default='"jaw"'>
Defines how facial regions—especially around the jawline—are parsed and blended.

**Options**: `"jaw"` or `"raw"`

**Example**: `"jaw"`
</ResponseField>

<ResponseField name="left_cheek_width" type="number" default="90">
Pixel width for blending region on the left cheek. Adjust wider to soften seam visibility.

**Range**: [50, 150]

**Example**: `90`
</ResponseField>

<ResponseField name="right_cheek_width" type="number" default="90">
Pixel width for blending region on the right cheek. Functions the same as `left_cheek_width`.

**Range**: [50, 150]

**Example**: `90`
</ResponseField>

<Tip>
These parameters are optional. Default values work well for most cases. Only adjust if you observe issues like face crop being too tight/loose or visible seams along the cheeks.
</Tip>
