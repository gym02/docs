---
title: "Overview"
description: "Build interactive real-time conversational digital humans with WebSocket-based API"
---

<Hero
  title="Real-time Digital Human API"
  subtitle="Create engaging real-time conversations with human-like digital avatars. Powered by direct audio-to-audio processing for the fastest response times."
/>

**NavTalk Real-time Digital Human API** enables you to build interactive conversational experiences with digital avatars that respond in real-time through WebSocket connections. With **sub-500ms latency** and seamless interruption handling, create natural, human-like interactions that feel truly conversational.

## Core Features

<CardGroup cols={3}>
  <Card
    title="Ultra-Low Latency"
    icon="bolt"
  >
    Sub-500ms end-to-end response times for real-time conversations
  </Card>
  <Card
    title="Real-time Rendering"
    icon="video"
  >
    Frame-accurate lip sync and emotion-driven facial expressions
  </Card>
  <Card
    title="Natural Conversations"
    icon="comments"
  >
    Human-like dialogue with emotional intelligence and empathetic responses
  </Card>
  <Card
    title="Multilingual Support"
    icon="language"
  >
    Over 50 languages with 95%+ recognition accuracy, seamless language switching
  </Card>
  <Card
    title="Context Management"
    icon="database"
  >
    Maintain conversation history and context across sessions
  </Card>
  <Card
    title="Preset Characters"
    icon="user"
  >
    Ready-to-use digital avatars for various use cases and industries
  </Card>
  <Card
    title="Custom Characters"
    icon="wand-magic-sparkles"
  >
    Create and deploy your own custom digital character avatars
  </Card>
  <Card
    title="Knowledge Base Integration"
    icon="book"
  >
    Connect enterprise or personal knowledge bases for expert-level, context-aware responses
  </Card>
  <Card
    title="Function Calling"
    icon="code"
  >
    Integrate external APIs and execute custom functions during conversations
  </Card>
</CardGroup>

## How It Works

The Real-time Digital Human API uses a **direct audio-to-audio processing pipeline** that eliminates traditional text conversion steps (STT and TTS), delivering unprecedented speed and natural conversation flow.

<AccordionGroup>
  <Accordion title="1. Audio Input" icon="microphone">
    Your application captures user audio input and sends audio streams through WebSocket connections. This layer handles real-time audio streaming and ensures continuous bidirectional communication for seamless dialogue.
  </Accordion>

  <Accordion title="2. Direct Processing" icon="bolt">
    GPT-realtime processes audio signals directly without text conversion steps. By eliminating Speech-to-Text (STT) and Text-to-Speech (TTS) transformations, the system achieves sub-500ms latency and enables natural interruption handling.
  </Accordion>

  <Accordion title="3. Audio Output" icon="volume-high">
    The processed audio response is generated in real-time and synchronized with video rendering. This layer delivers high-quality audio output with preserved fidelity, maintaining natural voice tone and emotional nuances.
  </Accordion>

  <Accordion title="4. Visual Rendering" icon="video">
    Frame-accurate lip sync and emotion-driven facial expressions are rendered in real-time, creating a lifelike visual presence synchronized with the audio output.
  </Accordion>
</AccordionGroup>


## Try Our Demo

We provide simple, single-page demos in multiple languages and platforms that you can clone and run with one click. To get started:

1. **Register for an account** and obtain your API key from the [dashboard](https://console.navtalk.ai/login#/dashboard)
2. **Clone the Samples repository**: `git clone https://github.com/navtalk/Samples.git`
3. **Configure your API key** in the demo files
4. **Run the demo** â€” each demo is a single-page application that works immediately

The [Samples repository](https://github.com/navtalk/Samples.git) includes ready-to-run examples for Web, Python, JavaScript, and other platforms to help you get started quickly.

