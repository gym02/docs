---
title: "WebRTC Connection"
description: "Learn how to establish WebRTC connections to receive audio and video responses from the NavTalk Real-time Digital Human API"
---

## WebRTC Connection

WebRTC connections are used to **receive the returned audio and video data** from the NavTalk API. After processing your audio input via WebSocket, the digital human's audio and video responses are delivered through WebRTC for optimal streaming performance.

<Note>
In the new unified API, WebRTC signaling messages (offer, answer, ICE candidates) are sent through the same WebSocket connection used for real-time API communication. You no longer need a separate WebRTC WebSocket connection.
</Note>

<Steps>
<Step title="Handle WebRTC Signaling Through Unified WebSocket">
  In the new unified API, WebRTC signaling messages are sent and received through the same WebSocket connection used for real-time API communication. You need to handle WebRTC events in your message handler:

<CodeGroup>
```javascript JavaScript
// Define event type constants (should be defined at the top of your file)
const NavTalkMessageType = Object.freeze({
    WEB_RTC_OFFER: "webrtc.signaling.offer",
    WEB_RTC_ANSWER: "webrtc.signaling.answer",
    WEB_RTC_ICE_CANDIDATE: "webrtc.signaling.iceCandidate",
    // ... other event types
});

// In your message handler (same socket used for real-time API)
async function handleReceivedMessage(data) {
  const nav_data = data.data;
  
  switch (data.type) {
    // ... other event handlers ...
    
    // WebRTC signaling events
    case NavTalkMessageType.WEB_RTC_OFFER:
      handleOffer(nav_data);
      break;
    
    case NavTalkMessageType.WEB_RTC_ANSWER:
      handleAnswer(nav_data);
      break;
    
    case NavTalkMessageType.WEB_RTC_ICE_CANDIDATE:
      handleIceCandidate(nav_data);
      break;
  }
}

// Helper functions to send WebRTC signaling messages
function sendOfferMessage(sdp) {
  const message = {
    type: NavTalkMessageType.WEB_RTC_OFFER,
    data: { sdp: sdp }
  };
  socket.send(JSON.stringify(message));
}

function sendAnswerMessage(sdp) {
  const message = {
    type: NavTalkMessageType.WEB_RTC_ANSWER,
    data: { sdp: sdp }
  };
  socket.send(JSON.stringify(message));
}

function sendIceMessage(candidate) {
  const message = {
    type: NavTalkMessageType.WEB_RTC_ICE_CANDIDATE,
    data: { candidate: candidate }
  };
  socket.send(JSON.stringify(message));
}
```

```python Python
# In your message handler (same websocket used for real-time API)
async def handle_messages(websocket):
    async for message in websocket:
        if isinstance(message, str):
            data = json.loads(message)
            nav_data = data.get('data')
            
            message_type = data.get('type')
            
            if message_type == 'webrtc.signaling.offer':
                await handle_offer(nav_data, websocket)
            elif message_type == 'webrtc.signaling.answer':
                await handle_answer(nav_data)
            elif message_type == 'webrtc.signaling.iceCandidate':
                await handle_ice_candidate(nav_data)
            # ... other event handlers ...

# Helper functions to send WebRTC signaling messages
async def send_offer_message(websocket, sdp):
    message = {
        'type': 'webrtc.signaling.offer',
        'data': { 'sdp': sdp }
    }
    await websocket.send(json.dumps(message))

async def send_answer_message(websocket, sdp):
    message = {
        'type': 'webrtc.signaling.answer',
        'data': { 'sdp': sdp }
    }
    await websocket.send(json.dumps(message))

async def send_ice_message(websocket, candidate):
    message = {
        'type': 'webrtc.signaling.iceCandidate',
        'data': { 'candidate': candidate }
    }
    await websocket.send(json.dumps(message))
```
</CodeGroup>

<Note>
**Important**: WebRTC signaling is now integrated into the unified WebSocket connection. You no longer need to:
- Create a separate WebRTC WebSocket connection
- Use `sessionId` as `userId` query parameter
- Send `{ type: 'create', targetSessionId: ... }` message

Instead, WebRTC offer/answer/ICE candidate messages are automatically handled through the same WebSocket connection using the event types shown above.
</Note>
</Step>

<Step title="Handle WebRTC Offer">
  When you receive an offer from the server, create a peer connection, set the remote description, create an answer, and send it back:

<CodeGroup>
```javascript JavaScript
let peerConnection;

// ICE server configuration for NAT traversal
const configuration = {
  iceServers: [
    { urls: 'stun:stun.l.google.com:19302' }
  ]
};

function handleOffer(message) {
  const offer = new RTCSessionDescription(message.sdp);
  console.log("Received offer SDP:", offer);
  
  // Fetch ICE servers configuration
  fetch('https://transfer.navtalk.ai/api/webrtc/generate-ice-servers', { method: 'POST' })
    .then(res => res.json())
    .then(data => {
      const servers = data?.data?.iceServers ?? data?.iceServers;
      if (Array.isArray(servers) && servers.length > 0) {
        configuration.iceServers = servers;
      }
      
      // Create RTCPeerConnection
      peerConnection = new RTCPeerConnection(configuration);
      
      // Set remote description
      peerConnection.setRemoteDescription(offer)
        .then(() => peerConnection.createAnswer())
        .then(answer => peerConnection.setLocalDescription(answer))
        .then(() => {
          // Send answer back to server through unified WebSocket
          sendAnswerMessage(peerConnection.localDescription);
        })
        .catch(err => console.error('Error handling offer:', err));
      
      // Handle incoming tracks (audio/video)
      peerConnection.ontrack = (event) => {
        console.log('Received remote track:', event);
        const remoteVideo = document.getElementById('character-video');
        if (remoteVideo) {
          remoteVideo.srcObject = event.streams[0];
          remoteVideo.play().catch(e => console.error('Video play failed:', e));
        }
      };
      
      // Handle ICE candidates
      peerConnection.onicecandidate = (event) => {
        if (event.candidate) {
          // Send ICE candidate through unified WebSocket
          sendIceMessage(event.candidate);
        }
      };
      
      // Monitor connection state
      peerConnection.oniceconnectionstatechange = () => {
        console.log('ICE connection state:', peerConnection.iceConnectionState);
        if (peerConnection.iceConnectionState === 'connected') {
          console.log('WebRTC connection fully established!');
        } else if (peerConnection.iceConnectionState === 'failed') {
          console.log('ICE connection failed');
        }
      };
    })
    .catch(err => console.error('Error fetching ICE servers:', err));
}
```

```python Python
# Python WebRTC implementation requires additional libraries
# such as aiortc or python-webrtc
# This is a conceptual example

async def handle_offer(message, websocket):
    from aiortc import RTCPeerConnection, RTCSessionDescription
    
    offer = RTCSessionDescription(sdp=message['sdp']['sdp'], type=message['sdp']['type'])
    
    pc = RTCPeerConnection()
    
    @pc.on('track')
    def on_track(track):
        print('Received track:', track.kind)
        # Handle incoming audio/video track
        # Play in appropriate media element
    
    await pc.setRemoteDescription(offer)
    answer = await pc.createAnswer()
    await pc.setLocalDescription(answer)
    
    # Send answer through unified WebSocket
    await send_answer_message(websocket, {
        'sdp': pc.localDescription.sdp,
        'type': pc.localDescription.type
    })
    
    # Handle ICE candidates
    @pc.on('icecandidate')
    def on_ice_candidate(candidate):
        if candidate:
            await send_ice_message(websocket, {
                'candidate': candidate.candidate,
                'sdpMid': candidate.sdpMid,
                'sdpMLineIndex': candidate.sdpMLineIndex
            })
```
</CodeGroup>
</Step>

<Step title="Handle ICE Candidates">
  Exchange ICE candidates to establish the optimal network path for media streaming:

<CodeGroup>
```javascript JavaScript
function handleIceCandidate(message) {
  const candidate = new RTCIceCandidate(message.candidate);
  
  if (peerConnection) {
    peerConnection.addIceCandidate(candidate)
      .then(() => console.log('ICE candidate added successfully'))
      .catch(err => console.error('Error adding ICE candidate:', err));
  }
}
```

```python Python
async def handle_ice_candidate(message):
    candidate_info = message['candidate']
    candidate = RTCIceCandidate(
        candidate=candidate_info['candidate'],
        sdpMid=candidate_info['sdpMid'],
        sdpMLineIndex=candidate_info['sdpMLineIndex']
    )
    if pc:
        await pc.addIceCandidate(candidate)
        print('ICE candidate added successfully')
```
</CodeGroup>
</Step>

<Step title="Display Video Stream">
  Display the received video stream in a video element:

<CodeGroup>
```javascript JavaScript
// HTML: <video id="character-video" autoplay playsinline></video>

peerConnection.ontrack = (event) => {
  console.log('Received remote track:', event);
  
  const remoteVideo = document.getElementById('character-video');
  if (remoteVideo && event.streams && event.streams[0]) {
    remoteVideo.srcObject = event.streams[0];
    
    // Start playback
    remoteVideo.play()
      .then(() => console.log('Video playback started'))
      .catch(e => console.error('Video play failed:', e));
  }
};
```

```python Python
# Python implementation depends on your GUI framework
# For web-based Python apps, you might use aiohttp + WebRTC
# or integrate with a frontend framework
```
</CodeGroup>
</Step>
</Steps>
