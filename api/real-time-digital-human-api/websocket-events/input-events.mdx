---
title: "Input Events"
description: "User speech detection and transcription events"
---

Input events track user speech detection and transcription. These events notify you when the user starts speaking, stops speaking, and when their speech has been transcribed.

## Event Types

### `input_audio_buffer.speech_started`
Triggered when the server detects that the user has started speaking.

**When to handle**: Stop any current audio playback and prepare for new input.

<CodeGroup>
```javascript JavaScript
case "input_audio_buffer.speech_started":
  console.log("Speech started detected by server.");
  stopCurrentAudioPlayback();
  audioQueue = [];
  isPlaying = false;
  playVideo = false;
  break;
```

```python Python
if data.get('type') == 'input_audio_buffer.speech_started':
    print("Speech started detected by server.")
    stop_current_audio_playback()
    audio_queue.clear()
    is_playing = False
    play_video = False
```
</CodeGroup>

**What to do**:
- Stop current AI response playback
- Clear audio queue
- Reset playback flags

### `input_audio_buffer.speech_stopped`
Triggered when the server detects that the user has stopped speaking.

**When to handle**: Process the user's speech and wait for AI response.

<CodeGroup>
```javascript JavaScript
case "input_audio_buffer.speech_stopped":
  console.log("Speech stopped detected by server.");
  // User has finished speaking, wait for transcription and response
  break;
```

```python Python
if data.get('type') == 'input_audio_buffer.speech_stopped':
    print("Speech stopped detected by server.")
    # User has finished speaking, wait for transcription and response
```
</CodeGroup>

### `conversation.item.input_audio_transcription.completed`
Triggered when the user's speech has been fully transcribed.

**Event data**:
- `transcript`: The complete transcribed text of user speech

**When to handle**: Display the user message in your chat interface and save to conversation history.

<CodeGroup>
```javascript JavaScript
case "conversation.item.input_audio_transcription.completed":
  console.log("Received transcription: " + data.transcript);
  
  // Display user message in chat
  const userMessageContainer = document.createElement('div');
  userMessageContainer.classList.add('character-chat-item', 'item-user');
  
  const userMessage = document.createElement('span');
  userMessage.textContent = data.transcript;
  userMessageContainer.appendChild(userMessage);
  
  const chatContent = document.querySelector('.ah-character-chat');
  chatContent.appendChild(userMessageContainer);
  chatContent.scrollTop = chatContent.scrollHeight;
  
  // Save to conversation history
  await appendRealtimeChatHistory("user", data.transcript);
  break;
```

```python Python
if data.get('type') == 'conversation.item.input_audio_transcription.completed':
    transcript = data.get('transcript')
    print(f"Received transcription: {transcript}")
    
    # Display user message in chat
    display_user_message(transcript)
    
    # Save to conversation history
    await append_chat_history("user", transcript)
```
</CodeGroup>

## Event Flow

```
User starts speaking
  ↓
Receive input_audio_buffer.speech_started
  ↓
Stop AI audio playback, clear queue
  ↓
[User continues speaking, keep sending audio chunks]
  ↓
User stops speaking
  ↓
Receive input_audio_buffer.speech_stopped
  ↓
Receive conversation.item.input_audio_transcription.completed
  ↓
Display user message, save to history
```

<Tip>
**Interruption Handling**: If the user starts speaking while the AI is responding, `input_audio_buffer.speech_started` will immediately stop the AI playback, enabling natural interruptions in the conversation.
</Tip>

